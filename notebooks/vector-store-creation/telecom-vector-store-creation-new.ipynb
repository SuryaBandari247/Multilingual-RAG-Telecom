{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telecom Multilingual Vector Store Creation\n",
    "\n",
    "## Overview\n",
    "This notebook creates a multilingual vector database for telecom customer service conversations using ChromaDB and BGE-M3 embeddings. The vector store enables semantic search across conversations in German, French, Italian, and English.\n",
    "\n",
    "## Key Components\n",
    "- **Data Source**: Processed telecom conversations with topic labels and language metadata\n",
    "- **Embedding Model**: BAAI/bge-m3 (1024-dimensional multilingual embeddings)\n",
    "- **Vector Database**: ChromaDB with persistent storage\n",
    "- **Languages**: German (deu), French (fra), Italian (ita), English (eng)\n",
    "- **Dataset**: ~40,000 training documents, 400 test documents\n",
    "\n",
    "## Workflow\n",
    "1. **Data Preparation**: Load processed conversations with topic labels\n",
    "2. **Train/Test Split**: Create balanced datasets across languages (10K train, 100 test per language)\n",
    "3. **Embedding Generation**: Generate BGE-M3 embeddings with GPU acceleration\n",
    "4. **Vector Store Creation**: Store embeddings in ChromaDB with metadata\n",
    "5. **Evaluation**: Test multilingual retrieval capabilities\n",
    "6. **Export**: Save retrieval evaluation results\n",
    "\n",
    "## Technical Specifications\n",
    "- **Batch Processing**: 64 documents per batch for memory efficiency\n",
    "- **GPU Optimization**: CUDA acceleration with memory management\n",
    "- **Storage**: Persistent ChromaDB database\n",
    "- **Retrieval**: Semantic similarity search with k=5 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-13T14:50:49.920445Z",
     "iopub.status.busy": "2025-07-13T14:50:49.920104Z",
     "iopub.status.idle": "2025-07-13T14:50:52.010091Z",
     "shell.execute_reply": "2025-07-13T14:50:52.008978Z",
     "shell.execute_reply.started": "2025-07-13T14:50:49.920401Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Basic Python environment setup with essential data science libraries\n",
    "# These are pre-installed in the Kaggle environment\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Check available input data files in the Kaggle environment\n",
    "# This helps verify that our datasets are properly loaded\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Note: Output files are saved to /kaggle/working/ which gets preserved\n",
    "# Temporary files can be written to /kaggle/temp/ but won't be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T14:50:52.011725Z",
     "iopub.status.busy": "2025-07-13T14:50:52.011107Z",
     "iopub.status.idle": "2025-07-13T14:52:29.184080Z",
     "shell.execute_reply": "2025-07-13T14:52:29.183102Z",
     "shell.execute_reply.started": "2025-07-13T14:50:52.011683Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Install required packages for multilingual embeddings and vector database\n",
    "\n",
    "!pip install -U FlagEmbedding\n",
    "!pip install langchain-chroma\n",
    "!pip install langchain-community\n",
    "!pip install langchain-huggingface\n",
    "!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T14:52:29.185611Z",
     "iopub.status.busy": "2025-07-13T14:52:29.185198Z",
     "iopub.status.idle": "2025-07-13T14:52:30.807403Z",
     "shell.execute_reply": "2025-07-13T14:52:30.806354Z",
     "shell.execute_reply.started": "2025-07-13T14:52:29.185579Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check installed versions of FlagEmbedding and LangChain components\n",
    "!pip list | grep -E 'FlagEmbedding|langchain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T14:52:30.810363Z",
     "iopub.status.busy": "2025-07-13T14:52:30.810081Z",
     "iopub.status.idle": "2025-07-13T14:53:06.597644Z",
     "shell.execute_reply": "2025-07-13T14:53:06.596726Z",
     "shell.execute_reply.started": "2025-07-13T14:52:30.810338Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import all necessary libraries for vector store creation\n",
    "from turtle import pd  # Note: This seems to be an error, should be corrected\n",
    "from FlagEmbedding import BGEM3FlagModel  # BGE-M3 multilingual embedding model\n",
    "from langchain_chroma import Chroma  # ChromaDB vector store integration\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings  # Hugging Face embeddings wrapper\n",
    "from langchain_community.document_loaders import TextLoader, CSVLoader  # Document loaders\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter  # Text chunking utility\n",
    "from langchain_openai.chat_models import ChatOpenAI  # OpenAI integration\n",
    "\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T17:10:52.237919Z",
     "iopub.status.busy": "2025-07-08T17:10:52.237569Z",
     "iopub.status.idle": "2025-07-08T17:11:00.067955Z",
     "shell.execute_reply": "2025-07-08T17:11:00.067267Z",
     "shell.execute_reply.started": "2025-07-08T17:10:52.237889Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the processed telecom conversation data with NER cleaning applied\n",
    "df = pd.read_csv(\"/kaggle/input/telecom-after-ner/after_ner.csv\", encoding='UTF-8')\n",
    "\n",
    "# Extract only the cleaned text and topic label columns for vector store creation\n",
    "# This reduces file size and focuses on the essential data\n",
    "df[['cleaned_text','topic_label']].to_csv(r\"/kaggle/working/cleaned_text.csv\")\n",
    "\n",
    "# Reload the cleaned dataset for further processing\n",
    "df_cleaned_text_metadata = pd.read_csv(r\"/kaggle/working/cleaned_text.csv\", encoding='UTF-8')\n",
    "df_cleaned_text_metadata.head()\n",
    "\n",
    "# Remove the automatically generated index column\n",
    "df_cleaned_text_metadata = df_cleaned_text_metadata.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T17:11:03.160152Z",
     "iopub.status.busy": "2025-07-08T17:11:03.159841Z",
     "iopub.status.idle": "2025-07-08T17:11:03.176261Z",
     "shell.execute_reply": "2025-07-08T17:11:03.175444Z",
     "shell.execute_reply.started": "2025-07-08T17:11:03.160126Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create balanced train/test datasets across multiple languages\n",
    "# Each language gets 10,000 training records and 100 test records\n",
    "\n",
    "# Training data: Select 10,000 records for each language\n",
    "train_deu = df_cleaned_text_metadata.iloc[0:10000].copy()  # German training data\n",
    "train_deu['language'] = 'deu'\n",
    "train_fra = df_cleaned_text_metadata.iloc[15000:25000]  # French training data\n",
    "train_fra['language'] = 'fra'\n",
    "train_ita = df_cleaned_text_metadata.iloc[30000:40000]  # Italian training data\n",
    "train_ita['language'] = 'ita'\n",
    "train_eng = df_cleaned_text_metadata.iloc[45000:55000]  # English training data\n",
    "train_eng['language'] = 'eng'\n",
    "\n",
    "# Combine all training data into a single dataframe\n",
    "train_df = pd.concat([train_deu, train_fra, train_ita, train_eng], ignore_index=True)\n",
    "\n",
    "# Testing data: Select 100 records for each language (non-overlapping with training)\n",
    "test_deu = df_cleaned_text_metadata.iloc[10000:10100]  # German test data\n",
    "test_deu['language'] = 'deu'\n",
    "test_fra = df_cleaned_text_metadata.iloc[25000:25100]  # French test data\n",
    "test_fra['language'] = 'fra'\n",
    "test_ita = df_cleaned_text_metadata.iloc[40000:40100]  # Italian test data\n",
    "test_ita['language'] = 'ita'\n",
    "test_eng = df_cleaned_text_metadata.iloc[55000:55100]  # English test data\n",
    "test_eng['language'] = 'eng'\n",
    "\n",
    "# Combine all test data into a single dataframe\n",
    "test_df = pd.concat([test_deu, test_fra, test_ita, test_eng], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T17:11:07.150110Z",
     "iopub.status.busy": "2025-07-08T17:11:07.149768Z",
     "iopub.status.idle": "2025-07-08T17:11:07.170620Z",
     "shell.execute_reply": "2025-07-08T17:11:07.169801Z",
     "shell.execute_reply.started": "2025-07-08T17:11:07.150084Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Preview the first 10 rows of training data\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T17:11:10.310757Z",
     "iopub.status.busy": "2025-07-08T17:11:10.310406Z",
     "iopub.status.idle": "2025-07-08T17:11:10.329470Z",
     "shell.execute_reply": "2025-07-08T17:11:10.328501Z",
     "shell.execute_reply.started": "2025-07-08T17:11:10.310726Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Analyze topic label diversity across training and testing datasets\n",
    "# This helps understand the variety of conversation topics available\n",
    "print(\"Total unique topic labels in training data:\", train_df['topic_label'].nunique())\n",
    "print(\"Total unique topic labels in testing data:\", test_df['topic_label'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T17:11:13.918348Z",
     "iopub.status.busy": "2025-07-08T17:11:13.918013Z",
     "iopub.status.idle": "2025-07-08T17:11:15.346455Z",
     "shell.execute_reply": "2025-07-08T17:11:15.345558Z",
     "shell.execute_reply.started": "2025-07-08T17:11:13.918322Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Visualize topic distribution across languages for top 15 topics\n",
    "# This helps identify which topics are most common and how they're distributed across languages\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "# Get top 15 topic labels in train and test datasets\n",
    "top_train_labels = train_df['topic_label'].value_counts().nlargest(15).index\n",
    "top_test_labels = test_df['topic_label'].value_counts().nlargest(15).index\n",
    "\n",
    "# Filter dataframes to include only top labels for clearer visualization\n",
    "train_top = train_df[train_df['topic_label'].isin(top_train_labels)]\n",
    "test_top = test_df[test_df['topic_label'].isin(top_test_labels)]\n",
    "\n",
    "# Create visualization for training data topic distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(data=train_top, x='topic_label', hue='language', order=top_train_labels)\n",
    "plt.title('Top 15 Topic Labels in Training Data')\n",
    "plt.xlabel('Topic Label')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Create visualization for testing data topic distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(data=test_top, x='topic_label', hue='language', order=top_test_labels)\n",
    "plt.title('Top 15 Topic Labels in Testing Data')\n",
    "plt.xlabel('Topic Label')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T17:11:20.051881Z",
     "iopub.status.busy": "2025-07-08T17:11:20.051152Z",
     "iopub.status.idle": "2025-07-08T17:11:20.521348Z",
     "shell.execute_reply": "2025-07-08T17:11:20.520493Z",
     "shell.execute_reply.started": "2025-07-08T17:11:20.051844Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Analyze common topic labels between training and testing datasets\n",
    "# This ensures both datasets cover similar conversation topics for proper evaluation\n",
    "common_labels = set(train_df['topic_label']).intersection(set(test_df['topic_label']))\n",
    "\n",
    "# Count occurrences of each common label in both datasets\n",
    "common_labels_count = {\n",
    "    label: {\n",
    "        'train': (train_df['topic_label'] == label).sum(),\n",
    "        'test': (test_df['topic_label'] == label).sum()\n",
    "    }\n",
    "    for label in common_labels\n",
    "}\n",
    "\n",
    "# Convert to DataFrame for easier analysis\n",
    "common_labels_df = pd.DataFrame.from_dict(common_labels_count, orient='index').reset_index()\n",
    "common_labels_df.columns = ['topic_label', 'train_count', 'test_count']\n",
    "common_labels = set(train_df['topic_label']).intersection(set(test_df['topic_label']))\n",
    "\n",
    "common_labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T17:11:23.795089Z",
     "iopub.status.busy": "2025-07-08T17:11:23.794684Z",
     "iopub.status.idle": "2025-07-08T17:11:25.658810Z",
     "shell.execute_reply": "2025-07-08T17:11:25.658123Z",
     "shell.execute_reply.started": "2025-07-08T17:11:23.795033Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save processed train and test datasets for future use\n",
    "# These will be used for vector store creation and evaluation\n",
    "print(\"Saving train and test dataframes to csv files...\")\n",
    "train_df.to_csv(r\"/kaggle/working/train_df.csv\", index=False)\n",
    "test_df.to_csv(r\"/kaggle/working/test_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T17:11:33.620374Z",
     "iopub.status.busy": "2025-07-08T17:11:33.619942Z",
     "iopub.status.idle": "2025-07-08T17:11:35.080274Z",
     "shell.execute_reply": "2025-07-08T17:11:35.079522Z",
     "shell.execute_reply.started": "2025-07-08T17:11:33.620341Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize CSV loader for LangChain document processing\n",
    "# The loader will treat 'cleaned_text' column as the source content for embeddings\n",
    "loader = CSVLoader(file_path='/kaggle/working/train_df.csv',\n",
    "                   encoding = 'UTF-8',\n",
    "                   source_column= 'cleaned_text')\n",
    "\n",
    "# Load documents from CSV into LangChain document format\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T17:11:36.702186Z",
     "iopub.status.busy": "2025-07-08T17:11:36.701869Z",
     "iopub.status.idle": "2025-07-08T17:11:36.706891Z",
     "shell.execute_reply": "2025-07-08T17:11:36.705830Z",
     "shell.execute_reply.started": "2025-07-08T17:11:36.702161Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Preview the structure of loaded documents\n",
    "# This shows how LangChain formats the document with content and metadata\n",
    "print(docs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T17:11:39.565890Z",
     "iopub.status.busy": "2025-07-08T17:11:39.565561Z",
     "iopub.status.idle": "2025-07-08T17:12:15.923042Z",
     "shell.execute_reply": "2025-07-08T17:12:15.921940Z",
     "shell.execute_reply.started": "2025-07-08T17:11:39.565859Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize BGE-M3 multilingual embedding model\n",
    "# BGE-M3 is optimized for multilingual semantic search with 1024-dimensional vectors\n",
    "# Using CUDA for GPU acceleration and normalizing embeddings for better similarity calculations\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-m3\",\n",
    "                                        model_kwargs={'device': 'cuda'},\n",
    "                                        encode_kwargs={\"normalize_embeddings\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T17:12:15.924626Z",
     "iopub.status.busy": "2025-07-08T17:12:15.924312Z",
     "iopub.status.idle": "2025-07-08T17:12:15.929023Z",
     "shell.execute_reply": "2025-07-08T17:12:15.928325Z",
     "shell.execute_reply.started": "2025-07-08T17:12:15.924601Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Configure CUDA memory allocation for better GPU memory management\n",
    "# This helps prevent out-of-memory errors when processing large batches\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T17:12:19.169873Z",
     "iopub.status.busy": "2025-07-08T17:12:19.169581Z",
     "iopub.status.idle": "2025-07-08T19:04:18.462707Z",
     "shell.execute_reply": "2025-07-08T19:04:18.461880Z",
     "shell.execute_reply.started": "2025-07-08T17:12:19.169849Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Individual record processing approach (slower but memory-efficient)\n",
    "# Initialize ChromaDB persistent client for data storage\n",
    "from chromadb import Client\n",
    "from chromadb.config import Settings\n",
    "from chromadb import PersistentClient\n",
    "\n",
    "# Create persistent ChromaDB client with local storage\n",
    "client = PersistentClient(path=\"/kaggle/working/chromadb\")\n",
    "collection = client.get_or_create_collection(\"telecom_vector_store\")\n",
    "\n",
    "from tqdm import tqdm  # Progress bar for long-running operations\n",
    "\n",
    "# Process each record individually with embedding generation\n",
    "# This approach is slower but uses less memory\n",
    "for idx, row in tqdm(train_df.iterrows(), total=len(train_df)):\n",
    "    chat_history = row['cleaned_text']  # Extract conversation text\n",
    "    metadata = {\n",
    "        \"language\": row['language'],\n",
    "        \"topic_label\": row['topic_label']\n",
    "    }\n",
    "    # Generate embedding for single document\n",
    "    embedding = embedding_model.embed_documents([chat_history])[0]\n",
    "    # Store in ChromaDB with metadata\n",
    "    collection.add(\n",
    "        embeddings=[embedding],\n",
    "        documents=[chat_history],\n",
    "        metadatas=[metadata],\n",
    "        ids=[str(idx)]\n",
    "    )\n",
    "\n",
    "print(f\"Total records processed: {collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Batch processing approach (faster and more efficient)\n",
    "# Process multiple documents simultaneously for better performance\n",
    "from chromadb import PersistentClient\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "# Initialize ChromaDB client\n",
    "client = PersistentClient(path=\"/kaggle/working/chromadb\")\n",
    "collection = client.get_or_create_collection(\"telecom_vector_store\")\n",
    "\n",
    "# Configure batch processing parameters\n",
    "batch_size = 64  # Process 64 documents at once for optimal GPU utilization\n",
    "num_batches = math.ceil(len(train_df) / batch_size)\n",
    "\n",
    "# Process data in batches for efficiency\n",
    "for batch_num in tqdm(range(num_batches), desc=\"Processing Batches\"):\n",
    "    start_idx = batch_num * batch_size\n",
    "    end_idx = min((batch_num + 1) * batch_size, len(train_df))\n",
    "    batch_df = train_df.iloc[start_idx:end_idx]\n",
    "\n",
    "    # Prepare batch data for embedding generation\n",
    "    texts = batch_df['cleaned_text'].tolist()\n",
    "    embeddings = embedding_model.embed_documents(texts)  # Generate embeddings for entire batch\n",
    "    metadatas = [\n",
    "        {\n",
    "            \"language\": row['language'],\n",
    "            \"topic_label\": row['topic_label']\n",
    "        }\n",
    "        for _, row in batch_df.iterrows()\n",
    "    ]\n",
    "    ids = [str(idx) for idx in batch_df.index]\n",
    "\n",
    "    # Insert entire batch into ChromaDB\n",
    "    collection.add(\n",
    "        embeddings=embeddings,\n",
    "        documents=texts,\n",
    "        metadatas=metadatas,\n",
    "        ids=ids\n",
    "    )\n",
    "\n",
    "print(f\"Total records processed: {collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create persistent ChromaDB client for long-term storage\n",
    "# This ensures data persists between notebook sessions\n",
    "from chromadb import PersistentClient\n",
    "persistent_client = PersistentClient(path=\"/kaggle/working/chromadb\")\n",
    "persistent_collection = persistent_client.get_or_create_collection(\"telecom_vector_store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T20:19:15.043179Z",
     "iopub.status.busy": "2025-07-08T20:19:15.042797Z",
     "iopub.status.idle": "2025-07-08T20:20:53.270307Z",
     "shell.execute_reply": "2025-07-08T20:20:53.269402Z",
     "shell.execute_reply.started": "2025-07-08T20:19:15.043147Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Migrate data from temporary to persistent collection in batches\n",
    "# This ensures data is properly stored for future use\n",
    "record_count = collection.count()\n",
    "batch_size = 1000  # Batch size for migration operations\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Transfer data in batches to avoid memory issues\n",
    "for i in tqdm(range(0, record_count, batch_size)):\n",
    "    batch = collection.get(\n",
    "        include=[\"embeddings\", \"documents\", \"metadatas\"],\n",
    "        limit=batch_size,\n",
    "        offset=i\n",
    "    )\n",
    "    # Add batch data to persistent collection\n",
    "    persistent_collection.add(\n",
    "        ids=batch['ids'],\n",
    "        embeddings=batch['embeddings'],\n",
    "        documents=batch['documents'],\n",
    "        metadatas=batch['metadatas']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T20:22:38.132479Z",
     "iopub.status.busy": "2025-07-08T20:22:38.132134Z",
     "iopub.status.idle": "2025-07-08T20:22:38.144624Z",
     "shell.execute_reply": "2025-07-08T20:22:38.143464Z",
     "shell.execute_reply.started": "2025-07-08T20:22:38.132448Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Verify that data migration was successful\n",
    "# Check the total count in the persistent collection\n",
    "print(\"Persistent count:\", persistent_collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T20:21:49.539366Z",
     "iopub.status.busy": "2025-07-08T20:21:49.539083Z",
     "iopub.status.idle": "2025-07-08T20:21:49.770229Z",
     "shell.execute_reply": "2025-07-08T20:21:49.769131Z",
     "shell.execute_reply.started": "2025-07-08T20:21:49.539345Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check the size of the ChromaDB database file\n",
    "# This helps monitor storage usage and performance\n",
    "ls -lh /kaggle/working/chromadb/chroma.sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T20:24:08.760020Z",
     "iopub.status.busy": "2025-07-08T20:24:08.759695Z",
     "iopub.status.idle": "2025-07-08T20:24:08.772381Z",
     "shell.execute_reply": "2025-07-08T20:24:08.771592Z",
     "shell.execute_reply.started": "2025-07-08T20:24:08.759991Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Preview sample documents from the collection\n",
    "# This helps verify data structure and content quality\n",
    "sample = collection.peek(1)\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T20:25:08.517810Z",
     "iopub.status.busy": "2025-07-08T20:25:08.517501Z",
     "iopub.status.idle": "2025-07-08T20:25:08.526455Z",
     "shell.execute_reply": "2025-07-08T20:25:08.525752Z",
     "shell.execute_reply.started": "2025-07-08T20:25:08.517786Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create LangChain-compatible vector store interface\n",
    "# This enables integration with LangChain retrieval chains\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"telecom_vector_store\",\n",
    "    embedding_function=embedding_model,\n",
    "    persist_directory=\"/kaggle/working/chromadb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-08T20:25:11.271875Z",
     "iopub.status.busy": "2025-07-08T20:25:11.271581Z",
     "iopub.status.idle": "2025-07-08T20:25:11.275833Z",
     "shell.execute_reply": "2025-07-08T20:25:11.274970Z",
     "shell.execute_reply.started": "2025-07-08T20:25:11.271851Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create retriever interface with k=5 for retrieving top 5 similar documents\n",
    "# This will be used for semantic search and RAG applications\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T15:10:14.275940Z",
     "iopub.status.busy": "2025-07-13T15:10:14.275614Z",
     "iopub.status.idle": "2025-07-13T15:10:14.282344Z",
     "shell.execute_reply": "2025-07-13T15:10:14.281345Z",
     "shell.execute_reply.started": "2025-07-13T15:10:14.275904Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Test retrieval functionality with a sample query\n",
    "# This verifies that semantic search is working correctly\n",
    "retriever.invoke(\"Problem with data connectivity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T14:53:06.602056Z",
     "iopub.status.busy": "2025-07-13T14:53:06.601668Z",
     "iopub.status.idle": "2025-07-13T14:53:16.997193Z",
     "shell.execute_reply": "2025-07-13T14:53:16.996303Z",
     "shell.execute_reply.started": "2025-07-13T14:53:06.601993Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Copy pre-existing database from input directory to working directory\n",
    "# This is useful when using a previously created vector store\n",
    "import shutil\n",
    "\n",
    "# Source: read-only input directory with existing ChromaDB\n",
    "source_dir = '/kaggle/input/telecom-vector-store-new/chromadb'\n",
    "\n",
    "# Destination: writable working directory\n",
    "destination_dir = '/kaggle/working/chromadb'\n",
    "\n",
    "# Copy the entire database directory if it doesn't already exist\n",
    "if not os.path.exists(destination_dir):\n",
    "    shutil.copytree(source_dir, destination_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T15:10:47.491426Z",
     "iopub.status.busy": "2025-07-13T15:10:47.491083Z",
     "iopub.status.idle": "2025-07-13T15:10:52.092582Z",
     "shell.execute_reply": "2025-07-13T15:10:52.091499Z",
     "shell.execute_reply.started": "2025-07-13T15:10:47.491398Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Reinitialize embedding model and vector store after copying database\n",
    "# This ensures proper connection to the copied ChromaDB\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-m3\",\n",
    "                                        model_kwargs={'device': 'cuda'},\n",
    "                                        encode_kwargs={\"normalize_embeddings\": True})\n",
    "\n",
    "# Connect to the copied vector store\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"telecom_vector_store\",\n",
    "    embedding_function=embedding_model,\n",
    "    persist_directory=\"/kaggle/working/chromadb\"\n",
    ")\n",
    "\n",
    "# Create retriever with k=5 for semantic search\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T15:11:01.610872Z",
     "iopub.status.busy": "2025-07-13T15:11:01.610495Z",
     "iopub.status.idle": "2025-07-13T15:11:01.615319Z",
     "shell.execute_reply": "2025-07-13T15:11:01.614412Z",
     "shell.execute_reply.started": "2025-07-13T15:11:01.610842Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define multilingual test queries for retrieval evaluation\n",
    "# These test queries cover common telecom issues in different languages\n",
    "language_texts = {\n",
    "    \"German\": \"Ich habe ein Problem mit meinem internationalen Sprach- und Datenroaming. Ich bin derzeit in LOC und die Anrufqualität ist sehr schlecht, mit viel statischem Rauschen. Außerdem kann ich mich nicht mit dem Internet verbinden. Ich habe bereits versucht, mein iPhone NUM neu zu starten, aber das hat das Problem nicht gelöst. Es ist frustrierend, dass mein Mobilfunkanbieter das Problem nicht direkt beh.\",\n",
    "    \"French\": \"J'ai un problème avec la configuration de mon nouvel appareil Samsung Galaxy SNUM Ultra. Je reçois constamment un message d'erreur indiquant que ma carte SIM n'est pas compatible, bien que j'aie vérifié en ligne et que cela devrait fonctionner. J'ai essayé de redémarrer mon téléphone plusieurs fois, mais cela n'a pas résolu le problème. Je suis frustré car j'essaie de le faire fonctionner depuis\",\n",
    "    \"Italian\": \"Ho un problema con il controllo dell'utilizzo dei dati del mio piano hotspot mobile. Sto cercando di verificare quanti dati ho consumato finora questo mese rispetto alla mia allocazione mensile. Ho bisogno di assistenza per accedere a queste informazioni sul mio account.\",\n",
    "    \"English\": \"I am facing a problem with adding an international roaming plan to my account. I've tried accessing my account online and through the mobile app, but I can't get it to work. I've been on hold for a long time, which is frustrating. When I tried to add the \\\"Global Traveler\\\" plan, the system wouldn't allow it due to an alleged issue with my billing address. However, I'm certain that my billing address is correct as I've been using the same one for years.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T15:26:44.988671Z",
     "iopub.status.busy": "2025-07-13T15:26:44.988388Z",
     "iopub.status.idle": "2025-07-13T15:26:45.045707Z",
     "shell.execute_reply": "2025-07-13T15:26:45.044988Z",
     "shell.execute_reply.started": "2025-07-13T15:26:44.988649Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Test retrieval with German query about roaming issues\n",
    "# This evaluates cross-language semantic search capabilities\n",
    "retriever_output = retriever.invoke(language_texts['German'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T15:41:53.355247Z",
     "iopub.status.busy": "2025-07-13T15:41:53.354878Z",
     "iopub.status.idle": "2025-07-13T15:41:53.552478Z",
     "shell.execute_reply": "2025-07-13T15:41:53.551545Z",
     "shell.execute_reply.started": "2025-07-13T15:41:53.355216Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Comprehensive multilingual retrieval evaluation\n",
    "# Test all language queries and analyze retrieved document metadata\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "class Document: # Document structure for compatibility\n",
    "    def __init__(self, id: str, metadata: Dict[str, Any], page_content: str):\n",
    "        self.id = id\n",
    "        self.metadata = metadata\n",
    "        self.page_content = page_content\n",
    "\n",
    "# Test queries for evaluation across all supported languages\n",
    "language_texts = {\n",
    "    \"German\": \"Ich habe ein Problem mit meinem internationalen Sprach- und Datenroaming. Ich bin derzeit in LOC und die Anrufqualität ist sehr schlecht, mit viel statischem Rauschen. Außerdem kann ich mich nicht mit dem Internet verbinden. Ich habe bereits versucht, mein iPhone NUM neu zu starten, aber das hat das Problem nicht gelöst. Es ist frustrierend, dass mein Mobilfunkanbieter das Problem nicht direkt beh.\",\n",
    "    \"French\": \"J'ai un problème avec la configuration de mon nouvel appareil Samsung Galaxy SNUM Ultra. Je reçois constamment un message d'erreur indiquant que ma carte SIM n'est pas compatible, bien que j'aie vérifié en ligne et que cela devrait fonctionner. J'ai essayé de redémarrer mon téléphone plusieurs fois, mais cela n'a pas résolu le problème. Je suis frustré car j'essaie de le faire fonctionner depuis\",\n",
    "    \"Italian\": \"Ho un problema con il controllo dell'utilizzo dei dati del mio piano hotspot mobile. Sto cercando di verificare quanti dati ho consumato finora questo mese rispetto alla mia allocazione mensile. Ho bisogno di assistenza per accedere a queste informazioni sul mio account.\",\n",
    "    \"English\": \"I am facing a problem with adding an international roaming plan to my account. I've tried accessing my account online and through the mobile app, but I can't get it to work. I've been on hold for a long time, which is frustrating. When I tried to add the \\\"Global Traveler\\\" plan, the system wouldn't allow it due to an alleged issue with my billing address. However, I'm certain that my billing address is correct as I've been using the same one for years.\"\n",
    "}\n",
    "\n",
    "data = []\n",
    "\n",
    "# Evaluate retrieval for each language query\n",
    "for lang_name, text_content in language_texts.items():\n",
    "    try:\n",
    "        response_documents: List[Document] = retriever.invoke(text_content)\n",
    "    except Exception as e:\n",
    "        print(f\"Error calling retriever for {lang_name}: {e}. Skipping this input.\")\n",
    "        continue \n",
    "\n",
    "    # Analyze each retrieved document's metadata\n",
    "    for i, doc in enumerate(response_documents):\n",
    "        if hasattr(doc, 'metadata') and isinstance(doc.metadata, dict):\n",
    "            topic_label = doc.metadata.get('topic_label')\n",
    "            language = doc.metadata.get('language')\n",
    "            # Store evaluation data for analysis\n",
    "            data.append({\n",
    "                'original_language_text': lang_name,\n",
    "                'document_rank': i + 1, # Rank of retrieved document\n",
    "                'topic_label': topic_label,\n",
    "                'language': language\n",
    "            })\n",
    "\n",
    "# Create evaluation dataframe\n",
    "df_retreiver_evaluation = pd.DataFrame(data)\n",
    "\n",
    "# Format display to show original language only once per group\n",
    "df_retreiver_evaluation['original_language_text'] = df_retreiver_evaluation['original_language_text'].mask(df_retreiver_evaluation['original_language_text'].duplicated(), '')\n",
    "\n",
    "df_retreiver_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T15:42:07.992288Z",
     "iopub.status.busy": "2025-07-13T15:42:07.991933Z",
     "iopub.status.idle": "2025-07-13T15:42:08.012859Z",
     "shell.execute_reply": "2025-07-13T15:42:08.012091Z",
     "shell.execute_reply.started": "2025-07-13T15:42:07.992260Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Export retrieval evaluation results for further analysis\n",
    "# This saves the multilingual retrieval performance data\n",
    "df_retreiver_evaluation.to_csv(r\"/kaggle/working/df_retreiver_evaluation.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6581613,
     "sourceId": 10629727,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7829091,
     "sourceId": 12413780,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7829232,
     "sourceId": 12413993,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
